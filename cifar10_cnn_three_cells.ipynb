{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe4ef07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1 — Imports & backend\n",
    "import os, random, numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Use TensorFlow as Keras backend (Keras 3)\n",
    "try:\n",
    "    keras.config.set_backend(\"tensorflow\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "print(\"TensorFlow:\", tf.__version__)\n",
    "print(\"Keras:\", keras.__version__)\n",
    "\n",
    "# Optional: reproducibility\n",
    "SEED = 123\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "random.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e76e957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2 — Data extraction (CIFAR-10), scaling, and stratified train/val split\n",
    "from tensorflow import keras as tfkeras  # for datasets\n",
    "\n",
    "# Load CIFAR-10 (50k train, 10k test)\n",
    "(x_train, y_train), (test_x, test_y) = tfkeras.datasets.cifar10.load_data()\n",
    "y_train = y_train.squeeze().astype(np.int64)\n",
    "test_y  = test_y.squeeze().astype(np.int64)\n",
    "\n",
    "# Scale to [0,1]\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "test_x  = test_x.astype(\"float32\")  / 255.0\n",
    "\n",
    "# Stratified validation split (10% of the 50k training set → 5k)\n",
    "x_train_real, x_val, y_train_real, y_val = train_test_split(\n",
    "    x_train, y_train, test_size=0.1, stratify=y_train, random_state=SEED\n",
    ")\n",
    "\n",
    "print(\"Train:\", x_train_real.shape, y_train_real.shape)\n",
    "print(\"Val:  \", x_val.shape,          y_val.shape)\n",
    "print(\"Test: \", test_x.shape,         test_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfef769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3 — Model definition and training (original toy CNN)\n",
    "import keras\n",
    "from keras import layers, callbacks, optimizers\n",
    "\n",
    "num_classes = 10\n",
    "input_shape = (32, 32, 3)\n",
    "\n",
    "# --- Data augmentation (kept modest) ---\n",
    "data_aug = keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.05),\n",
    "    layers.RandomTranslation(0.05, 0.05),\n",
    "    # (No RandomZoom on 32x32 to avoid too much info loss)\n",
    "], name=\"data_aug\")\n",
    "\n",
    "# --- Small but solid CNN ---\n",
    "inputs = keras.Input(shape=input_shape)\n",
    "x = data_aug(inputs)\n",
    "\n",
    "# Block 1\n",
    "x = layers.Conv2D(32, 3, padding=\"same\", use_bias=False)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation(\"relu\")(x)\n",
    "x = layers.Conv2D(32, 3, padding=\"same\", use_bias=False)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation(\"relu\")(x)\n",
    "x = layers.MaxPooling2D()(x)\n",
    "x = layers.Dropout(0.25)(x)\n",
    "\n",
    "# Block 2\n",
    "x = layers.Conv2D(64, 3, padding=\"same\", use_bias=False)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation(\"relu\")(x)\n",
    "x = layers.Conv2D(64, 3, padding=\"same\", use_bias=False)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation(\"relu\")(x)\n",
    "x = layers.MaxPooling2D()(x)\n",
    "x = layers.Dropout(0.25)(x)\n",
    "\n",
    "# Head\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "model = keras.Model(inputs, outputs, name=\"cifar10_cnn_toy\")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(1e-3),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# --- Useful callbacks ---\n",
    "cbs = [\n",
    "    callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_accuracy\", factor=0.5, patience=2, verbose=1, min_lr=3e-5\n",
    "    ),\n",
    "    callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\", patience=4, restore_best_weights=True\n",
    "    ),\n",
    "]\n",
    "\n",
    "# --- Train ---\n",
    "history = model.fit(\n",
    "    x_train_real, y_train_real,\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=30,                 # EarlyStopping will cap this\n",
    "    batch_size=1024,           # On Colab T4 you can try bigger; on CPU lower if needed\n",
    "    verbose=1,\n",
    "    callbacks=cbs\n",
    ")\n",
    "\n",
    "# --- Evaluate on the held-out test set ---\n",
    "test_loss, test_acc = model.evaluate(test_x, test_y, verbose=0)\n",
    "print(f\"Test accuracy: {test_acc:.3f}\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}