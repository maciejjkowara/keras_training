{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ac1e790a-b81b-47e0-b06e-5be89aca4d6b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2393 raw analyses\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import re\n",
        "import json\n",
        "\n",
        "# 1. Read the entire file\n",
        "raw_text = Path(\"equity_analyses.txt\").read_text(encoding=\"utf-8\")\n",
        "\n",
        "# 2. Split into individual analyses.\n",
        "#    Each analysis ends with </analysis>. There may be trailing whitespace.\n",
        "raw_blocks = re.split(r\"</analysis>\\s*\", raw_text)\n",
        "# The last split is often empty if the file ends with </analysis>\n",
        "raw_blocks = [b for b in raw_blocks if b.strip()]\n",
        "\n",
        "print(f\"Found {len(raw_blocks)} raw analyses\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "5487d75a-a079-4f75-9b76-bdb003107998",
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_tag(block: str, tag: str, required: bool = False):\n",
        "    \"\"\"\n",
        "    Extracts the content inside <tag>...</tag> from the text block.\n",
        "    If required=True and the tag is not found, returns None (we can later drop those examples).\n",
        "    \"\"\"\n",
        "    # Note: for 'fund name' the tag literally is <fund name>...</fund name>\n",
        "    pattern = fr\"<{tag}>(.*?)</{tag}>\"\n",
        "    m = re.search(pattern, block, flags=re.DOTALL)\n",
        "    if not m:\n",
        "        return None\n",
        "    return m.group(1).strip()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "124522c8-3845-4007-adef-317c9bbeedb9",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2393"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "records = []\n",
        "\n",
        "for i, block in enumerate(raw_blocks):\n",
        "    # Defensive: trim leading/trailing whitespace\n",
        "    b = block.strip()\n",
        "\n",
        "    # Some files may or may not have an explicit <analysis> open tag.\n",
        "    # If yours always has \"<analysis>\" at the beginning, you can strip it:\n",
        "    # b = b.replace(\"<analysis>\", \"\", 1).strip()\n",
        "\n",
        "    record = {\n",
        "        \"fund_name\":      extract_tag(b, \"fund name\"),\n",
        "        \"asset_class\":    extract_tag(b, \"asset_class\"),\n",
        "        \"category\":       extract_tag(b, \"category\"),\n",
        "        \"date\":           extract_tag(b, \"date\"),\n",
        "        \"author\":         extract_tag(b, \"author\"),\n",
        "        \"people_rating\":  extract_tag(b, \"people_rating\"),\n",
        "        \"process_rating\": extract_tag(b, \"process_rating\"),\n",
        "        \"summary\":        extract_tag(b, \"summary\"),\n",
        "        \"people\":         extract_tag(b, \"people\"),\n",
        "        \"process\":        extract_tag(b, \"process\"),\n",
        "        \"portfolio\":      extract_tag(b, \"portfolio\"),\n",
        "        \"performance\":    extract_tag(b, \"performance\"),\n",
        "    }\n",
        "\n",
        "    records.append(record)\n",
        "\n",
        "len(records)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "0137fffa-0c9c-43d2-9959-48a4bb3c306a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total records: 2393\n",
            "Clean records with all required fields: 2393\n"
          ]
        }
      ],
      "source": [
        "required_fields = [\"summary\", \"people\", \"process\", \"portfolio\", \"performance\"]\n",
        "\n",
        "clean_records = []\n",
        "for r in records:\n",
        "    if all(r[field] is not None and r[field].strip() for field in required_fields):\n",
        "        clean_records.append(r)\n",
        "\n",
        "print(f\"Total records: {len(records)}\")\n",
        "print(f\"Clean records with all required fields: {len(clean_records)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "c233d435-5fa5-456e-82cf-35be80be6773",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved 2393 records to equity_analyses_structured.jsonl\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "out_path = Path(\"equity_analyses_structured.jsonl\")\n",
        "\n",
        "with out_path.open(\"w\", encoding=\"utf-8\") as f:\n",
        "    for r in clean_records:\n",
        "        f.write(json.dumps(r, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "print(f\"Saved {len(clean_records)} records to {out_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f5df4d5-9c66-4764-a921-672e29bad551",
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q transformers datasets accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "ab7329ea-61b2-409f-9f30-bfb64460b695",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 2393 valid records\n",
            "Skipped 0 malformed lines\n",
            "Sample keys from first record: dict_keys(['fund_name', 'asset_class', 'category', 'date', 'author', 'people_rating', 'process_rating', 'summary', 'people', 'process', 'portfolio', 'performance'])\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "from json import JSONDecodeError\n",
        "\n",
        "DATA_PATH = Path(\"equity_analyses_structured.jsonl\")\n",
        "\n",
        "records = []\n",
        "bad_count = 0\n",
        "\n",
        "with DATA_PATH.open(\"r\", encoding=\"utf-8\") as f:\n",
        "    for i, line in enumerate(f, start=1):\n",
        "        try:\n",
        "            obj = json.loads(line)\n",
        "        except JSONDecodeError as e:\n",
        "            bad_count += 1\n",
        "            print(f\"Skipping malformed line {i}: {e}\")\n",
        "            continue\n",
        "        records.append(obj)\n",
        "\n",
        "print(f\"Loaded {len(records)} valid records\")\n",
        "print(f\"Skipped {bad_count} malformed lines\")\n",
        "\n",
        "print(\"Sample keys from first record:\", records[0].keys())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "eee4b7a1-1a61-4e5b-9cf7-3cf88eca0bb1",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "44990a7712324609ab8127db71858b27",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cb55ec5548ad4121ad2ca3ef4fa0b2c3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "def467fa5d934e8982ab4cd49f2896f9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "437b2c317d1b4939bdf73a1612b1f56a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3b954181cc7a485eb78860ba85dd6a58",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9f15e0ec429149cb84e9e52112edfbd2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9d3aca8c580d4166bcd511f5e82d06d0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model and tokenizer loaded.\n"
          ]
        }
      ],
      "source": [
        "# Load a pretrained Flan-T5 model for zero-shot summarization\n",
        "MODEL_NAME = \"google/flan-t5-base\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)\n",
        "\n",
        "print(\"Model and tokenizer loaded.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "41d4d7b5-c910-4536-a945-8dc1b3c9f814",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== FUND NAME ===\n",
            "4D Global Infrastructure AUD Hedged\n",
            "\n",
            "=== GENERATED SUMMARY (Flan-T5, zero-shot) ===\n",
            "4D Global Infrastructure underperformed during the 2024 calendar year, in part due to an underweight\n",
            "exposure to the US and allocations in Brazil\n",
            "\n",
            "=== HUMAN SUMMARY (Morningstar analyst) ===\n",
            "4D Global Infrastructure\u2019s exposure to emerging markets presents potential upsides, yet its\n",
            "dependence on portfolio manager Sarah Shaw tempers our confidence.  Shaw brings multidecade\n",
            "experience and a distinctive lens on emerging-markets infrastructure, honed during her tenure\n",
            "managing RARE Infrastructure\u2019s Emerging Markets Fund from 2006 to 2010. Shaw\u2019s deep familiarity with\n",
            "these regions positions her well to navigate their complexities, though the strategy\u2019s reliance on\n",
            "her expertise introduces key-person risk.   Additionally, supporting internal macroeconomic\n",
            "forecasting and country risk assessments is Tim Snelgrove, head of markets and trading. Having\n",
            "completed a yearlong transition with his predecessor, Snelgrove has a sound grasp of the process.\n",
            "However, given the absence of a track record as a sole macroeconomist, we remain conscious of his\n",
            "ongoing contributions.   A quality, value approach with a pronounced exposure to emerging markets\n",
            "separates itself and offers potential for outperformance. The inclusion of emerging markets with\n",
            "demonstrated insights into the region provides confidence that the manager can effectively leverage\n",
            "the expanded opportunity set. However, these regions are typically avoided by peers as they\n",
            "introduce elevated country risks. For example, in 2024, Brazilian holdings faced pressure amid a\n",
            "rising-rate environment fueled by government spending. Shaw remained unfazed; her confidence was\n",
            "supported by unconventional wisdom in the debt financing accessible in these regions. Additionally,\n",
            "Shaw has been dynamic in portfolio positioning. Early into covid, the strategy rapidly increased\n",
            "cash to the maximum allocation (10%) before redeploying into airports. While an initially sluggish\n",
            "recovery heavily detracted, the position eventually returned in spades. These examples underscore\n",
            "the strategy\u2019s differentiated approach but also highlight the need for investors to tolerate periods\n",
            "of underperformance.  In summary, 4D Global Infrastructure\u2019s emerging-markets tilt offers\n",
            "outperformance potential, but the strategy\u2019s success hinges heavily on a single manager. The primary\n",
            "vehicle from which this strategy\u2019s pillar ratings are derived is 4D Global Infrastructure Fund\n",
            "(Unhedged), ticker 41388.\n"
          ]
        }
      ],
      "source": [
        "import textwrap\n",
        "\n",
        "def build_input_from_record(rec):\n",
        "    \"\"\"Format one analysis into a single input string for the model.\"\"\"\n",
        "    return (\n",
        "        \"summarize_fund_analysis:\\n\"\n",
        "        \"[PEOPLE]\\n\" + rec[\"people\"] + \"\\n\\n\"\n",
        "        \"[PROCESS]\\n\" + rec[\"process\"] + \"\\n\\n\"\n",
        "        \"[PORTFOLIO]\\n\" + rec[\"portfolio\"] + \"\\n\\n\"\n",
        "        \"[PERFORMANCE]\\n\" + rec[\"performance\"]\n",
        "    )\n",
        "\n",
        "# Pick one example (you can change the index to inspect others)\n",
        "example = records[0]\n",
        "input_text = build_input_from_record(example)\n",
        "\n",
        "# Tokenize\n",
        "inputs = tokenizer(\n",
        "    input_text,\n",
        "    return_tensors=\"pt\",\n",
        "    max_length=1024,      # truncate long analyses for now\n",
        "    truncation=True,\n",
        ")\n",
        "\n",
        "# Generate a summary (zero-shot)\n",
        "output_ids = model.generate(\n",
        "    **inputs,\n",
        "    max_new_tokens=256,\n",
        "    num_beams=4,\n",
        "    length_penalty=1.0,\n",
        "    no_repeat_ngram_size=3,\n",
        ")\n",
        "\n",
        "generated_summary = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "\n",
        "print(\"=== FUND NAME ===\")\n",
        "print(example[\"fund_name\"])\n",
        "print()\n",
        "\n",
        "print(\"=== GENERATED SUMMARY (Flan-T5, zero-shot) ===\")\n",
        "print(textwrap.fill(generated_summary, width=100))\n",
        "print()\n",
        "\n",
        "print(\"=== HUMAN SUMMARY (Morningstar analyst) ===\")\n",
        "print(textwrap.fill(example[\"summary\"], width=100))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "1c18d09d-72c8-4612-820d-bf8df9f391ad",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2393"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def build_input(rec):\n",
        "    return (\n",
        "        \"summarize_fund_analysis:\\n\"\n",
        "        \"[PEOPLE]\\n\" + rec[\"people\"] + \"\\n\\n\"\n",
        "        \"[PROCESS]\\n\" + rec[\"process\"] + \"\\n\\n\"\n",
        "        \"[PORTFOLIO]\\n\" + rec[\"portfolio\"] + \"\\n\\n\"\n",
        "        \"[PERFORMANCE]\\n\" + rec[\"performance\"]\n",
        "    )\n",
        "\n",
        "dataset = []\n",
        "\n",
        "for rec in records:\n",
        "    dataset.append({\n",
        "        \"input\": build_input(rec),\n",
        "        \"target\": rec[\"summary\"],\n",
        "        \"fund_name\": rec[\"fund_name\"],  # optional, useful for debugging later\n",
        "    })\n",
        "\n",
        "len(dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "b62dc3f0-60d4-46bb-a85a-513fc895c1f4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: 1914, Val: 239, Test: 240\n",
            "Example train record keys: dict_keys(['input', 'target', 'fund_name'])\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "# For reproducibility\n",
        "random.seed(42)\n",
        "\n",
        "indices = list(range(len(dataset)))\n",
        "random.shuffle(indices)\n",
        "\n",
        "n_total = len(indices)\n",
        "n_train = int(0.8 * n_total)\n",
        "n_val   = int(0.1 * n_total)\n",
        "# rest goes to test\n",
        "n_test  = n_total - n_train - n_val\n",
        "\n",
        "train_indices = indices[:n_train]\n",
        "val_indices   = indices[n_train:n_train + n_val]\n",
        "test_indices  = indices[n_train + n_val:]\n",
        "\n",
        "train_data = [dataset[i] for i in train_indices]\n",
        "val_data   = [dataset[i] for i in val_indices]\n",
        "test_data  = [dataset[i] for i in test_indices]\n",
        "\n",
        "print(f\"Train: {len(train_data)}, Val: {len(val_data)}, Test: {len(test_data)}\")\n",
        "print(\"Example train record keys:\", train_data[0].keys())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "599fce90-57e2-4486-ba53-a6d9372fb6d4",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7e0593a22a8f4e3fba2feec30bf0ab37",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1914 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/jovyan/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:4034: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a56bcd25c5ed4ac2aff75eecfbfe6b4b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/239 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset({\n",
            "    features: ['input_ids', 'attention_mask', 'labels'],\n",
            "    num_rows: 1914\n",
            "})\n",
            "Dataset({\n",
            "    features: ['input_ids', 'attention_mask', 'labels'],\n",
            "    num_rows: 239\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "from datasets import Dataset\n",
        "from transformers import DataCollatorForSeq2Seq\n",
        "\n",
        "# Create HF datasets from our Python lists\n",
        "train_ds = Dataset.from_list(train_data)\n",
        "val_ds   = Dataset.from_list(val_data)\n",
        "\n",
        "max_input_length = 1024      # truncate body sections to this many tokens\n",
        "max_target_length = 384      # allow multi-paragraph summaries\n",
        "\n",
        "def preprocess_batch(batch):\n",
        "    # Tokenize inputs\n",
        "    model_inputs = tokenizer(\n",
        "        batch[\"input\"],\n",
        "        max_length=max_input_length,\n",
        "        truncation=True,\n",
        "    )\n",
        "\n",
        "    # Tokenize targets (labels)\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(\n",
        "            batch[\"target\"],\n",
        "            max_length=max_target_length,\n",
        "            truncation=True,\n",
        "        )\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "train_tokenized = train_ds.map(preprocess_batch, batched=True, remove_columns=train_ds.column_names)\n",
        "val_tokenized   = val_ds.map(preprocess_batch, batched=True, remove_columns=val_ds.column_names)\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
        "\n",
        "print(train_tokenized)\n",
        "print(val_tokenized)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c75831f8-0b5b-499f-97cb-392e7677323c",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_584/1616619494.py:28: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "/home/jovyan/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='15' max='720' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 15/720 08:39 < 7:49:48, 0.03 it/s, Epoch 0.06/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "output_dir = \"./flan_t5_fund_summary\"\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "\n",
        "    # older versions use \"eval_strategy\", not \"evaluation_strategy\"\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "\n",
        "    logging_steps=50,\n",
        "\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=2,\n",
        "\n",
        "    gradient_accumulation_steps=4,\n",
        "\n",
        "    num_train_epochs=3,\n",
        "    learning_rate=3e-5,\n",
        "    weight_decay=0.01,\n",
        "\n",
        "    # drop unsupported arguments\n",
        "    # predict_with_generate=True,\n",
        "    # report_to=[],\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_tokenized,\n",
        "    eval_dataset=val_tokenized,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c2f1bd2-42e2-4850-bd97-30c72df2d838",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "file_history": [],
    "kernelspec": {
      "display_name": "morningstar-internal/analyticslab-ai:5611",
      "language": "python",
      "name": "conda-store://morningstar-internal/analyticslab-ai:5611"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}