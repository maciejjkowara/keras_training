{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtwcVkLlrBzM"
      },
      "source": [
        "# Keras Multi-Output Classification - Bond Data\n",
        "Learning exercise: Predicting level_2 and level_3 from bond characteristics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "6AsQk_YqrYGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yPJNdEDQrBzP"
      },
      "outputs": [],
      "source": [
        "# Setup\n",
        "!pip install keras --upgrade -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hagpR3prBzQ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "\n",
        "import keras\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "print(f\"Keras version: {keras.__version__}\")\n",
        "print(f\"Backend: {keras.backend.backend()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zoxR9nefrBzQ"
      },
      "outputs": [],
      "source": [
        "# Load data\n",
        "# TODO: Upload your bond dataset (CSV file)\n",
        "df = pd.read_excel('mstar_core_bond_index_oct_data.xlsx')\n",
        "\n",
        "# Quick data check\n",
        "print(df.shape)\n",
        "print(df.head())\n",
        "print(df.info())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check unique values in our target variables\n",
        "print(\"level_2 unique values:\", df['level_2'].unique())\n",
        "print(\"level_2 counts:\\n\", df['level_2'].value_counts())\n",
        "print(\"\\nlevel_3 unique values:\", df['level_3'].unique())\n",
        "print(\"level_3 counts:\\n\", df['level_3'].value_counts())\n",
        "print(\"\\nrating unique values:\", df['rating'].unique())\n",
        "print(\"rating counts:\\n\", df['rating'].value_counts())"
      ],
      "metadata": {
        "id": "FpQVWmgkr2Ab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate features and targets\n",
        "X_numerical = df[['oas', 'yield', 'duration', 'convexity', 'coupon']].values\n",
        "X_rating = df['rating'].values\n",
        "y_level2 = df['level_2'].values\n",
        "y_level3 = df['level_3'].values\n",
        "\n",
        "print(\"Numerical features shape:\", X_numerical.shape)\n",
        "print(\"Rating feature shape:\", X_rating.shape)\n",
        "print(\"Target level_2 shape:\", y_level2.shape)\n",
        "print(\"Target level_3 shape:\", y_level3.shape)\n",
        "\n",
        "# Count unique classes for later\n",
        "num_classes_level2 = df['level_2'].nunique()\n",
        "num_classes_level3 = df['level_3'].nunique()\n",
        "num_ratings = df['rating'].nunique()\n",
        "\n",
        "print(f\"\\nNumber of classes - level_2: {num_classes_level2}, level_3: {num_classes_level3}\")\n",
        "print(f\"Number of rating categories: {num_ratings}\")"
      ],
      "metadata": {
        "id": "JZkvO0Wpscql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train/test split\n",
        "# We need to split all our inputs and both outputs\n",
        "X_num_train, X_num_test, X_rating_train, X_rating_test, y_level2_train, y_level2_test, y_level3_train, y_level3_test = train_test_split(\n",
        "    X_numerical,\n",
        "    X_rating,\n",
        "    y_level2,\n",
        "    y_level3,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y_level2  # Stratify by level_2 to maintain class balance\n",
        ")\n",
        "\n",
        "print(\"Training set size:\", X_num_train.shape[0])\n",
        "print(\"Test set size:\", X_num_test.shape[0])\n",
        "print(f\"Split ratio: {X_num_train.shape[0] / len(df):.1%} train, {X_num_test.shape[0] / len(df):.1%} test\")"
      ],
      "metadata": {
        "id": "l1unD82ntNIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recreate the StringLookup layers WITHOUT OOV token\n",
        "rating_lookup = keras.layers.StringLookup(output_mode=\"int\", num_oov_indices=0)\n",
        "level2_lookup = keras.layers.StringLookup(output_mode=\"int\", num_oov_indices=0)\n",
        "level3_lookup = keras.layers.StringLookup(output_mode=\"int\", num_oov_indices=0)\n",
        "\n",
        "# Adapt them to the training data\n",
        "rating_lookup.adapt(X_rating_train)\n",
        "level2_lookup.adapt(y_level2_train)\n",
        "level3_lookup.adapt(y_level3_train)\n",
        "\n",
        "print(\"Rating vocabulary size:\", rating_lookup.vocabulary_size())\n",
        "print(\"Level 2 vocabulary size:\", level2_lookup.vocabulary_size())\n",
        "print(\"Level 3 vocabulary size:\", level3_lookup.vocabulary_size())"
      ],
      "metadata": {
        "id": "ShpO6Iz2t3Vj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define input layers\n",
        "input_numerical = keras.Input(shape=(5,), name='numerical_features')\n",
        "input_rating = keras.Input(shape=(1,), dtype='string', name='rating')\n",
        "\n",
        "print(\"Input layers created:\")\n",
        "print(f\"  Numerical input: {input_numerical}\")\n",
        "print(f\"  Rating input: {input_rating}\")"
      ],
      "metadata": {
        "id": "4kSDqfXuvJJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply preprocessing layers\n",
        "rating_encoded = rating_lookup(input_rating)\n",
        "numerical_normalized = normalizer(input_numerical)\n",
        "\n",
        "print(\"Preprocessing applied:\")\n",
        "print(f\"  Rating encoded: {rating_encoded}\")\n",
        "print(f\"  Numerical normalized: {numerical_normalized}\")"
      ],
      "metadata": {
        "id": "gr2kXDP7vsWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simpler approach: just look at the vocabulary mappings\n",
        "print(\"Rating vocabulary mapping:\")\n",
        "vocab = rating_lookup.get_vocabulary()\n",
        "for i, rating in enumerate(vocab):\n",
        "    print(f\"  {i}: '{rating}'\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Sample of original data (first 5 rows):\")\n",
        "print(\"=\"*50)\n",
        "print(\"\\nNumerical features:\")\n",
        "print(X_num_train[:5])\n",
        "print(\"\\nRating values:\")\n",
        "print(X_rating_train[:5])\n",
        "print(\"\\nAfter encoding, these ratings would become:\")\n",
        "for rating in X_rating_train[:5]:\n",
        "    idx = vocab.index(rating) if rating in vocab else 0\n",
        "    print(f\"  '{rating}' -> {idx}\")"
      ],
      "metadata": {
        "id": "EtD4yAL1v8DW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten rating (it's shape (None, 1), we want (None,))\n",
        "rating_flat = keras.layers.Flatten()(rating_encoded)\n",
        "\n",
        "# Concatenate all features\n",
        "combined_features = keras.layers.Concatenate()([rating_flat, numerical_normalized])\n",
        "\n",
        "print(\"Features combined:\")\n",
        "print(f\"  Combined shape: {combined_features}\")"
      ],
      "metadata": {
        "id": "_0JrFJkhwp5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shared hidden layers\n",
        "x = keras.layers.Dense(64, activation='relu', name='hidden_1')(combined_features)\n",
        "x = keras.layers.Dense(32, activation='relu', name='hidden_2')(x)\n",
        "\n",
        "print(\"Hidden layers added:\")\n",
        "print(f\"  After hidden_1 (64 units): {x}\")"
      ],
      "metadata": {
        "id": "rxjSC2VHyGG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Output branch for level_2 (6 classes)\n",
        "output_level2 = keras.layers.Dense(\n",
        "    num_classes_level2,\n",
        "    activation='softmax',\n",
        "    name='level_2_output'\n",
        ")(x)\n",
        "\n",
        "# Output branch for level_3 (28 classes)\n",
        "output_level3 = keras.layers.Dense(\n",
        "    num_classes_level3,\n",
        "    activation='softmax',\n",
        "    name='level_3_output'\n",
        ")(x)\n",
        "\n",
        "print(\"Output layers created:\")\n",
        "print(f\"  level_2 output: {output_level2}\")\n",
        "print(f\"  level_3 output: {output_level3}\")"
      ],
      "metadata": {
        "id": "mXH8zO-_1NZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the full model\n",
        "model = keras.Model(\n",
        "    inputs=[input_numerical, input_rating],\n",
        "    outputs=[output_level2, output_level3],\n",
        "    name='bond_classifier'\n",
        ")\n",
        "\n",
        "print(\"Model created!\")\n",
        "print(\"\\nModel summary:\")\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "cjdUiL9W1vmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss={\n",
        "        'level_2_output': 'sparse_categorical_crossentropy',\n",
        "        'level_3_output': 'sparse_categorical_crossentropy'\n",
        "    },\n",
        "    metrics={\n",
        "        'level_2_output': ['accuracy'],\n",
        "        'level_3_output': ['accuracy']\n",
        "    }\n",
        ")\n",
        "\n",
        "print(\"Model compiled!\")\n",
        "print(\"Ready to train.\")"
      ],
      "metadata": {
        "id": "aPJR8Vqx1ws9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Encode target variables to integers\n",
        "y_level2_train_encoded = np.array(level2_lookup(y_level2_train.reshape(-1, 1))).flatten()\n",
        "y_level2_test_encoded = np.array(level2_lookup(y_level2_test.reshape(-1, 1))).flatten()\n",
        "\n",
        "y_level3_train_encoded = np.array(level3_lookup(y_level3_train.reshape(-1, 1))).flatten()\n",
        "y_level3_test_encoded = np.array(level3_lookup(y_level3_test.reshape(-1, 1))).flatten()\n",
        "\n",
        "print(\"Targets encoded!\")\n",
        "print(f\"Training samples: {len(y_level2_train_encoded)}\")\n",
        "print(f\"Test samples: {len(y_level2_test_encoded)}\")\n",
        "print(f\"\\nSample encoded level_2 targets: {y_level2_train_encoded[:5]}\")\n",
        "print(f\"Sample encoded level_3 targets: {y_level3_train_encoded[:5]}\")"
      ],
      "metadata": {
        "id": "E4W4w10T2I_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "    [X_num_train, tf.constant(X_rating_train.reshape(-1, 1), dtype=tf.string)],\n",
        "    {'level_2_output': y_level2_train_encoded,\n",
        "     'level_3_output': y_level3_train_encoded},\n",
        "    validation_split=0.2,\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"\\nTraining complete!\")"
      ],
      "metadata": {
        "id": "9gXfFTcV2dvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create figure with subplots\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "# Plot level_2 loss\n",
        "axes[0, 0].plot(history.history['level_2_output_loss'], label='Training')\n",
        "axes[0, 0].plot(history.history['val_level_2_output_loss'], label='Validation')\n",
        "axes[0, 0].set_title('Level 2 Loss')\n",
        "axes[0, 0].set_xlabel('Epoch')\n",
        "axes[0, 0].set_ylabel('Loss')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(True)\n",
        "\n",
        "# Plot level_2 accuracy\n",
        "axes[0, 1].plot(history.history['level_2_output_accuracy'], label='Training')\n",
        "axes[0, 1].plot(history.history['val_level_2_output_accuracy'], label='Validation')\n",
        "axes[0, 1].set_title('Level 2 Accuracy')\n",
        "axes[0, 1].set_xlabel('Epoch')\n",
        "axes[0, 1].set_ylabel('Accuracy')\n",
        "axes[0, 1].legend()\n",
        "axes[0, 1].grid(True)\n",
        "\n",
        "# Plot level_3 loss\n",
        "axes[1, 0].plot(history.history['level_3_output_loss'], label='Training')\n",
        "axes[1, 0].plot(history.history['val_level_3_output_loss'], label='Validation')\n",
        "axes[1, 0].set_title('Level 3 Loss')\n",
        "axes[1, 0].set_xlabel('Epoch')\n",
        "axes[1, 0].set_ylabel('Loss')\n",
        "axes[1, 0].legend()\n",
        "axes[1, 0].grid(True)\n",
        "\n",
        "# Plot level_3 accuracy\n",
        "axes[1, 1].plot(history.history['level_3_output_accuracy'], label='Training')\n",
        "axes[1, 1].plot(history.history['val_level_3_output_accuracy'], label='Validation')\n",
        "axes[1, 1].set_title('Level 3 Accuracy')\n",
        "axes[1, 1].set_xlabel('Epoch')\n",
        "axes[1, 1].set_ylabel('Accuracy')\n",
        "axes[1, 1].legend()\n",
        "axes[1, 1].grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rGqNiUp32y6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on test data\n",
        "test_results = model.evaluate(\n",
        "    [X_num_test, tf.constant(X_rating_test.reshape(-1, 1), dtype=tf.string)],\n",
        "    {'level_2_output': y_level2_test_encoded,\n",
        "     'level_3_output': y_level3_test_encoded},\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Test Results:\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Total Loss: {test_results[0]:.4f}\")\n",
        "print(f\"Level 2 Loss: {test_results[1]:.4f}\")\n",
        "print(f\"Level 3 Loss: {test_results[2]:.4f}\")\n",
        "print(f\"Level 2 Accuracy: {test_results[3]:.4f} ({test_results[3]*100:.2f}%)\")\n",
        "print(f\"Level 3 Accuracy: {test_results[4]:.4f} ({test_results[4]*100:.2f}%)\")"
      ],
      "metadata": {
        "id": "X6f4hX8t48ok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "\n",
        "# Make predictions on test set\n",
        "predictions = model.predict(\n",
        "    [X_num_test, tf.constant(X_rating_test.reshape(-1, 1), dtype=tf.string)],\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "# Get predicted classes (argmax of probabilities)\n",
        "y_pred_level2 = np.argmax(predictions[0], axis=1)\n",
        "y_pred_level3 = np.argmax(predictions[1], axis=1)\n",
        "\n",
        "# Create confusion matrices\n",
        "cm_level2 = confusion_matrix(y_level2_test_encoded, y_pred_level2)\n",
        "cm_level3 = confusion_matrix(y_level3_test_encoded, y_pred_level3)\n",
        "\n",
        "# Get class names\n",
        "level2_classes = level2_lookup.get_vocabulary()\n",
        "level3_classes = level3_lookup.get_vocabulary()\n",
        "\n",
        "# Plot Level 2 confusion matrix\n",
        "fig, axes = plt.subplots(1, 2, figsize=(18, 6))\n",
        "\n",
        "sns.heatmap(cm_level2, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=level2_classes, yticklabels=level2_classes,\n",
        "            ax=axes[0])\n",
        "axes[0].set_title('Level 2 Confusion Matrix')\n",
        "axes[0].set_ylabel('True Label')\n",
        "axes[0].set_xlabel('Predicted Label')\n",
        "\n",
        "# Plot Level 3 confusion matrix\n",
        "sns.heatmap(cm_level3, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=level3_classes, yticklabels=level3_classes,\n",
        "            ax=axes[1])\n",
        "axes[1].set_title('Level 3 Confusion Matrix')\n",
        "axes[1].set_ylabel('True Label')\n",
        "axes[1].set_xlabel('Predicted Label')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.yticks(rotation=0)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print detailed classification report for level_3\n",
        "print(\"\\nLevel 3 Classification Report:\")\n",
        "print(\"=\"*80)\n",
        "print(classification_report(y_level3_test_encoded, y_pred_level3,\n",
        "                           target_names=level3_classes, zero_division=0))"
      ],
      "metadata": {
        "id": "EImuYiR95drq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Biy4Ikgr6Zu_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}